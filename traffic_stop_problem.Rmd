---
title: "Traffic Stops"
output: html_notebook
author: "Ryan Gan"
date: "2018-04-27"
editor_options: 
  chunk_output_type: inline
---

## Set Up

Loading tidyverse library.

```{r library}
# tidyverse library
library(tidyverse)
```

Read in Montana and Vermont data.

```{r read}
# read montana
mt <- read_csv("./data/MT_cleaned.csv")
# read vermont
vt <- read_csv("./data/VT_cleaned.csv")
```

## Question 1:

What proportion of traffic stops in Montana involved male drivers? In other words, divide the number of traffic stops involving male drivers by the total number of stops.

```{r pr_males}
# pr stops for males
format(prop.table(xtabs(~ driver_gender, mt, addNA = T)), nsmall = 10)
```

## Question 2:

How many more times likely are you to be arrested in Montana during a traffic stop if you have out of state plates?

```{r risk_out_of_state}
# quasipoisson model to compare incidence of arrest for out of state vs in state
mod <- glm(is_arrested ~ out_of_state, mt, family="quasipoisson"(link="log"))
# risk ratio of arrest | out of state
format(exp(mod$coefficients[2]), nsmall = 10)
```

## Question 3: 

Chi-square test to test if likelihood for arrest is differnt from in and out of state. Poisson only gives Z statistic, so I'll have to use the chi.sq function on the 2x2 table.

```{r chisq_arrest}
# contengency table
arrest_tab <- xtabs(~out_of_state + is_arrested , mt)
# chisq test
format(chisq.test(arrest_tab)$statistic, nsmall=10)
```

## Question 4:

What proportion of traffic stops in Montana resulted in speeding violations? In other words, find the number of violations that include "Speeding" in the violation description and divide that number by the total number of stops (or rows in the Montana dataset).

```{r speeding}
# find any violation that has "speeding"" in violation
mt <- mt %>%
  # add new variable speeding by detecting any violation as speeding
  mutate(speeding = str_detect(violation, regex("speed", ignore_case = T)))

# speeding proportion
format(prop.table(xtabs(~speeding, mt)), nsmall = 10)
```

## Question 5:

How much more likely does a traffic stop in Montana result in a DUI than a traffic stop in Vermont? To compute the proportion of traffic stops that result in a DUI, divide the number of stops with "DUI" in the violation description by the total number of stops.

```{r dui}
# dui mt vector
dui_mt <- str_detect(mt$violation, regex("DUI", ignore_case = T))
# dui vt vector
dui_vt <- str_detect(vt$violation, regex("DUI", ignore_case = T))

# prop of dui in mt vs vt
format(prop.table(xtabs(~dui_mt))[2]/prop.table(xtabs(~dui_vt))[2], nsmall=10)
```

## Question 6:

What is the extrapolated, average manufacture year of vehicles involved in traffic stops in Montana in 2020? To answer this question, calculate the average vehicle manufacture year for each year's traffic stops. Extrapolate using a linear regression.

```{r lin_reg}
# extract stop year from stop date and convert car year to numeric
mt <- mt %>% 
  mutate(stop_year = lubridate::year(stop_date),
         vehicle_year = as.numeric(vehicle_year))

# checking car year by date to see if it's linear
ggplot(mt, aes(x=stop_year, y=vehicle_year)) +
  geom_point()

# linear model
year_mod <- lm(vehicle_year ~ stop_year, mt)
# day model
day_mod <- lm(vehicle_year ~ stop_date, mt)
# 2020 prediction data
pred_data <- data.frame(stop_year = 2020, stop_date = as.Date("2020-01-01"))
# predict 2020 based on year_mod
format(predict(year_mod, newdata = pred_data), nsmall=10)
# predict 2020 on jan 1 based on day mod; might as well go with day estimate
format(predict(day_mod, newdata = pred_data), nsmall=10)
```

```{r pval}
# p-value for model
format(anova(day_mod), nsmall=10)
```

## Question 6:

Combining both the Vermont and Montana datasets, find the hours when the most and least number of traffic stops occurred. What is the difference in the total number of stops that occurred in these two hours? Hours range from 00 to 23. Round stop times down to compute this difference.

```{r mt_vt_hours}
# using dplyr::bind_rows and only keep state and stop time
stop_time_data <- bind_rows(select(vt, state, stop_time), 
                            select(mt, state, stop_time)) %>% 
  mutate(hour = lubridate::hour(stop_time))

# visualize density of stop time hour
ggplot(stop_time_data, aes(x=hour)) +
  geom_density()

# visualize density of stop time as time
ggplot(stop_time_data, aes(x=stop_time)) +
  geom_density()

# find frequency of stops by hour
stop_time_freq <- stop_time_data %>% 
  group_by(hour) %>% 
  summarise(n = n()) %>% 
  filter(!is.na(hour))

# min and max hour
min_hour <- filter(stop_time_freq, n == min(n))
max_hour <- filter(stop_time_freq, n == max(n))
# different in freq
format(max_hour$n - min_hour$n, nsmall=10)
```

## Question 7:

We can use the traffic stop locations to estimate the areas of the counties in Montana. Represent each county as an ellipse with semi-axes given by a single standard deviation of the longitude and latitude of stops within that county. What is the area, in square kilometers, of the largest county measured in this manner? Please ignore unrealistic latitude and longitude coordinates.

```{r lat_lon}
# visualize lat/lon of montana
ggplot(mt, aes(x=lon,y=lat)) +
  geom_point()

# constrain mt to points in extent
mt_sp <- mt %>% 
  filter(lat <= 49 & lat >= 44 & lon <= -104) %>% 
  # find mean and sd for each county
  group_by(county_name) %>% 
  summarise(mu_lat = mean(lat), sd_lat = sd(lat), min_lat = min(lat), 
            max_lat = max(lat), mu_lon = mean(lon), sd_lon = sd(lon),
            min_lon = min(lon), max_lon = max(lon)) %>% 
  filter(!is.na(county_name)) %>% 
  # convert std dev of degrees to km, accounting for degree of lat for lon
  mutate(rlon_km = sd_lon*(6371 * acos(sin(mu_lat*pi/180)^2 +
            cos(mu_lat*pi/180)^2 * cos((mu_lon+.5)*pi/180 -
            (mu_lon-.5)*pi/180))),
         rlat_km = sd_lat*(6371 * acos(sin((mu_lat -.5)*pi/180) * 
            sin((mu_lat+.5)*pi/180) + cos((mu_lat-.5)*pi/180) *
            cos((mu_lat+.5)*pi/180))),
         area_km = pi*rlon_km*rlat_km)

# max area km2
format(max(mt_sp$area_km), nsmall = 10)
```


```{r check_points}
# check that mu lat lon is the centroid of points in gallatin county
gallatin_sp <- mt %>% 
  filter(lat <= 49 & lat >= 44 & lon <= -104) %>% 
  filter(county_name == "Gallatin County")

# gallatin polygon shape
gallatin_shape <- map_data("county", region = "montana") %>% 
  filter(subregion == "gallatin") %>% 
  rename(lon = long)

 
# plot mean lat lons of traffic stops
ggplot(gallatin_sp, aes(x=lon, y=lat)) +
  geom_point() +
  geom_point(data = filter(mt_sp, county_name == "Gallatin County"), 
             aes(x=mu_lon, y=mu_lat), color = "blue")  +
  geom_polygon(data=gallatin_shape, aes(x=lon,y=lat, group=group),
               fill = NA, color = "red")
```

